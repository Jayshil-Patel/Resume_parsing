{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jaysh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jaysh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword counts: {'python': 2, 'java': 2, 'data structures': 0, 'machine learning': 0, 'dsa': 0}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Download NLTK data files (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def extract_keywords(resume_text, keywords):\n",
    "    # Tokenize the resume text\n",
    "    tokens = word_tokenize(resume_text.lower())\n",
    "    \n",
    "    # Remove punctuation and stop words\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    \n",
    "    # Count occurrences of each keyword\n",
    "    keyword_counts = Counter(tokens)\n",
    "    \n",
    "    # Filter counts for the specific keywords we are interested in\n",
    "    keyword_summary = {key: keyword_counts[key.lower()] for key in keywords}\n",
    "    \n",
    "    return keyword_summary\n",
    "\n",
    "# Example resume text\n",
    "resume_text = \"\"\"\n",
    "Experienced software engineer skilled in Python, Java, and data structures. \n",
    "Proficient in machine learning, artificial intelligence, and web development. \n",
    "Extensive experience with Python and Java for backend development, as well as data analysis.\n",
    "\"\"\"\n",
    "\n",
    "# Define keywords to look for\n",
    "keywords = ['python', 'java', 'data structures', 'machine learning', 'dsa']\n",
    "\n",
    "# Extract and display keyword counts\n",
    "keyword_counts = extract_keywords(resume_text, keywords)\n",
    "print(\"Keyword counts:\", keyword_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
